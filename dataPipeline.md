# 220916
# 빅데이터 파이프라인 : 데이터를 모아서 내가 원하는 목적을 만들어주는 모델에 맞게 넣어주는 과정
데이터 처리량이 많기 때문에 최대한 동시에 많은 데이터를 많이 처리해야하고 그런 방법론이 많고 그 중 하나 배운 것이 함수형 패러다임
데이터 즉면에서는 동시에 여러 데이터를 처리할 수 있는 자료형(list, tuple) 등을 쓴다.

이러한 문제를 해결하기 위한 방법
1. 속도가 필요한 부부은 C언어로 처리하고, 대용량 데이터를 다루는 자료 구조 등을 c언어가 하는 방식 대로 처리
2. 데이터가 matrix가 기본 단위?이고 메트릭스만 빨리 처리해도 자료를 다루기(처리하기) 좋다.
3. matlab에서 사용하는 기능, 자료처리 기능 등을 모아서 새로 파이선으로 만들어 놓은 것이. numpy

# numpy : vector와 matrix를 처리하고 다루기 위해 서드파티로 만든 데이타 셋
파이선 자체에도 array가 존재하나 처리가 다르다. sequence, homogenius, mutable이라 연산자 처리가 원하는 바가 다르다.
element-wise 연산을 지원하지 않는다. 훨씬 c언어스러운 타입을 가진다. int16, int64 등

속도가 빠른 원인
1. data type의 범위 - 값의 범위를 줄이면 줄일 수록 연산 속도라 빠르다.
2. vectorization으로 연산할 수 있다.: thread 처럼 연산이 나눠져있는 묶음으로 각각을 연산하는 기능.

속도를 더 빠르게 할 수 있는 방법
1. 하드웨어 성능을 최적화 한다. (GPU, multi processor, 분할 컴퓨팅)
2. compiler를 사용한다. 다른 언어로 작동시키는 파이선. 파이선으로 만든 파이선도 있고 심지어 빠르다.
3. glue language의 특징을 이용해 다른 언어와 같이 사용하기 좋게한다.
4. 알고리즘 / data structure

### 용어 정리
- de facto : 사실상 표준, 밑에서의 표준
- standard : 위에서의 표준
- recommendation : 만든 사람은 추천, 받아드리는 사람은 표준

- domestic specific 언어 : 매트랩같이 특정 영역에 전문성을 가진 언어

## 속도가 빠른 원인 - 데이터 구조
ndarray는 데이터들의 주소가 기본적으로 연속적이고 head에 데이터 타입을 넣어서 다음값을 찾는 등의 연산이 없다.
다른 데이터 타입과 호환이 좋다. \_\_array__ 만 있으면 넘파이 데이터로 만들 수 있다.

## 속도가 빠른 원인 - Vectorization
데이터 크기가 작으면 넘파이로 변환하는 리소스가 더 커서 오히려 느린 경우가 있다. (배열 100개 이하)

numpy는 indexing과 slicing을 동시에 할 수 있다.
```
a = np.arange(25).reshape(5,5)
a[1] #=> array([4,5,6,7,8,9])
a[1,3:5] #=> array(8,9)
a[0,1] #=> 1

a[3:, [0,1,3]] #=> array([[15,16,18],
                        # [20,21,23])

a[2::2, ::2]    #=>array([[10,12,14],
                        # [20,22,24]])
# A[start:end:step]
# 2차원까지는 둘이 같다.
a[1,...]
a[1,:]
a = np.arange(24).reshape(2,3,4)
print(a[1,1,1])
print(a[:,:,3] == a[...,3])
```